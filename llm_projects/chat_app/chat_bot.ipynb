{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "79f3ba5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import HuggingFacePipeline\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain, SequentialChain\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain_community.llms import Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d82dc528",
   "metadata": {},
   "outputs": [],
   "source": [
    "token = \"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\"  # your HF token here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4884a862",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "login(token)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5efdc894",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': [{'role': 'user', 'content': 'Who are you?'},\n",
       "   {'role': 'assistant',\n",
       "    'content': 'I\\'m an artificial intelligence model known as Llama. Llama stands for \"Large Language Model Meta AI.\"'}]}]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use a pipeline as a high-level helper\n",
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"text-generation\", model=\"meta-llama/Llama-3.2-1B-Instruct\", device=\"cpu\",       # will spread across CPU+GPU\n",
    "    torch_dtype=\"float32\")\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Who are you?\"},\n",
    "]\n",
    "pipe(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "17c70398",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/lk/23npv5w93yvfg4q5_4b_sq7h0000gn/T/ipykernel_53599/3650147293.py:1: LangChainDeprecationWarning: The class `HuggingFacePipeline` was deprecated in LangChain 0.0.37 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFacePipeline``.\n",
      "  llm=HuggingFacePipeline(pipeline=pipe)\n"
     ]
    }
   ],
   "source": [
    "llm=HuggingFacePipeline(pipeline=pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "dc88eec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_restaurant_name_and_items(cuisine):\n",
    "    template = \"\"\"\n",
    "    You are a expert in different cuisines around the world. \n",
    "    I want to open a restaurant for {cuisine} food. Suggest one fancy name for my restaurant and what are the menu items that I can serve in my restaurant.\n",
    "    Give me the suggested name and menu items only.\n",
    "    \"\"\"\n",
    "    prompt = PromptTemplate.from_template(template)\n",
    "    prompt.format(cuisine=cuisine)\n",
    "    chain = LLMChain(llm=llm, prompt=prompt)\n",
    "    response = chain.invoke(cuisine)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c484faf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cuisine': 'Mexican', 'text': '\\n    You are a expert in different cuisines around the world. \\n    I want to open a restaurant for Mexican food. Suggest one fancy name for my restaurant and what are the menu items that I can serve in my restaurant.\\n    Give me the suggested name and menu items only.\\n     The name of the restaurant should be \"El Cazador\" which means \"The Hunter\" in Spanish. \\n    The name is inspired by the Mexican tradition of hunting and the idea of being a hunter of flavors and ingredients.\\n\\n    **Menu Items:**\\n\\n    **Appetizers**\\n    1. \"El Jardín de la Muerte\" (The Garden of Death) - Fried plantain chips with spicy salsa and avocado\\n    2. \"El Cañón de la Sierra\" (The Canyon of the Sierra) - Grilled chorizo and corn tortilla with chipotle aioli\\n    3. \"El Cazador\\'s Tostada\" - Crispy corn tortilla topped with grilled shrimp, pickled onions, and cilantro-lime crema\\n\\n    **Tacos**\\n    1. \"Taco de la Abuela\" - Grilled skirt steak, sliced radish, cilantro, and queso fresco\\n    2. \"El Pescador\" - Pan-seared fish, sliced mango, and cilantro-lime crema\\n    3. \"Taco de la Sopa\" - Crispy tortilla topped with slow-cooked chicken, pickled red onion, and'}\n"
     ]
    }
   ],
   "source": [
    "print(generate_restaurant_name_and_items(\"Mexican\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2731d025",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_startup_ideas(industry, budget):\n",
    "    template = \"\"\" \n",
    "    You are a expert in different industries and expert in generating startup ideas. \n",
    "    When you are given an industry and a budget, you will generate two best startup ideas that are within the budget.\n",
    "    And explain initial steps to start the startup. The industry is {industry} and the budget is {budget}.\n",
    "    \"\"\"\n",
    "    prompt= PromptTemplate.from_template(template)\n",
    "    prompt.format(industry=industry, budget=budget)\n",
    "    chain = LLMChain(llm=llm, prompt=prompt)\n",
    "    response = chain.run({\"industry\":industry, \"budget\":budget})\n",
    "    return response\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4a4a866e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "    You are a expert in different industries and expert in generating startup ideas. \n",
      "    When you are given an industry and a budget, you will generate two best startup ideas that are within the budget.\n",
      "    And explain initial steps to start the startup. The industry is AI and the budget is 100000.\n",
      "     You will also provide you analysis of the industry and the budget, as well as the potential risks and challenges.\n",
      "\n",
      "    Here is an example of what the output might look like:\n",
      "    ```\n",
      "    Industry: AI\n",
      "    Budget: $100,000\n",
      "    Best Startup Ideas:\n",
      "    1. AI-powered chatbot for customer service\n",
      "    2. AI-driven predictive maintenance for industrial equipment\n",
      "    Initial Steps:\n",
      "    1. Conduct market research and analysis\n",
      "    2. Validate the idea with a small group of customers\n",
      "    3. Develop a minimum viable product (MVP)\n",
      "    4. Test and iterate on the MVP\n",
      "    Potential Risks and Challenges:\n",
      "    1. High competition from established players\n",
      "    2. Regulatory hurdles and compliance issues\n",
      "    3. High upfront costs for research and development\n",
      "    4. Uncertainty about customer adoption and retention\n",
      "    Analysis:\n",
      "    Industry Overview:\n",
      "    AI is a rapidly growing industry with increasing adoption in various sectors, including customer service, healthcare, and finance. The market is expected to reach $190 billion by 2025, with a compound annual growth rate (CAGR) of 25.5%.\n",
      "    Budget Breakdown:\n",
      "    1. Market research and analysis:\n"
     ]
    }
   ],
   "source": [
    "print(generate_startup_ideas(\"AI\", 100000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c972681e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "you are a helpful assistant.\n",
      "\n",
      "Hello, how are you?\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Hello, how are you?',\n",
       " 'chat_history': '',\n",
       " 'response': '\\nyou are a helpful assistant.\\n\\nHello, how are you?\\nI\\'m feeling a bit stuck on a problem I\\'m working on, and I could really use some guidance.\\n\\nI have a project that involves creating a system to manage a library\\'s catalog, where users can add, remove, and search for books. The system should be able to handle a large number of books with varying metadata.\\n\\nI\\'ve been trying to implement a simple implementation using Python, but I\\'m running into some issues. Specifically, I\\'m having trouble with handling the case where a user tries to remove a book that is currently being searched by another user.\\n\\nHere\\'s a simplified representation of the problem:\\n\\n```python\\nclass Book:\\n    def __init__(self, title, author, id):\\n        self.title = title\\n        self.author = author\\n        self.id = id\\n\\nclass Library:\\n    def __init__(self):\\n        self.books = {}\\n\\n    def add_book(self, book):\\n        self.books[book.id] = book\\n\\n    def remove_book(self, book_id):\\n        if book_id in self.books:\\n            del self.books[book_id]\\n        else:\\n            print(\"Book not found\")\\n\\n    def search_book(self, query):\\n        results = []\\n        for book in self.books.values():\\n            if query.lower() in book.title.lower'}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory \n",
    "\n",
    "template = \"\"\"\n",
    "you are a helpful assistant.\n",
    "{chat_history}\n",
    "{input}\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"input\", \"chat_history\"])\n",
    "\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\")\n",
    "\n",
    "memory.clear()\n",
    "\n",
    "conversation_chain = ConversationChain(\n",
    "    llm=llm,\n",
    "    prompt=prompt,\n",
    "    memory=memory,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "conversation_chain.invoke({\"input\": \"Hello, how are you?\"})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "7b4b638b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "you are a helpful assistant.\n",
      "Human: Hello, how are you?\n",
      "AI: \n",
      "you are a helpful assistant.\n",
      "\n",
      "Hello, how are you?\n",
      "I'm feeling a bit stuck on a problem I'm working on, and I could really use some guidance.\n",
      "\n",
      "I have a project that involves creating a system to manage a library's catalog, where users can add, remove, and search for books. The system should be able to handle a large number of books with varying metadata.\n",
      "\n",
      "I've been trying to implement a simple implementation using Python, but I'm running into some issues. Specifically, I'm having trouble with handling the case where a user tries to remove a book that is currently being searched by another user.\n",
      "\n",
      "Here's a simplified representation of the problem:\n",
      "\n",
      "```python\n",
      "class Book:\n",
      "    def __init__(self, title, author, id):\n",
      "        self.title = title\n",
      "        self.author = author\n",
      "        self.id = id\n",
      "\n",
      "class Library:\n",
      "    def __init__(self):\n",
      "        self.books = {}\n",
      "\n",
      "    def add_book(self, book):\n",
      "        self.books[book.id] = book\n",
      "\n",
      "    def remove_book(self, book_id):\n",
      "        if book_id in self.books:\n",
      "            del self.books[book_id]\n",
      "        else:\n",
      "            print(\"Book not found\")\n",
      "\n",
      "    def search_book(self, query):\n",
      "        results = []\n",
      "        for book in self.books.values():\n",
      "            if query.lower() in book.title.lower\n",
      "write a poem about a cat\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'write a poem about a cat',\n",
       " 'chat_history': 'Human: Hello, how are you?\\nAI: \\nyou are a helpful assistant.\\n\\nHello, how are you?\\nI\\'m feeling a bit stuck on a problem I\\'m working on, and I could really use some guidance.\\n\\nI have a project that involves creating a system to manage a library\\'s catalog, where users can add, remove, and search for books. The system should be able to handle a large number of books with varying metadata.\\n\\nI\\'ve been trying to implement a simple implementation using Python, but I\\'m running into some issues. Specifically, I\\'m having trouble with handling the case where a user tries to remove a book that is currently being searched by another user.\\n\\nHere\\'s a simplified representation of the problem:\\n\\n```python\\nclass Book:\\n    def __init__(self, title, author, id):\\n        self.title = title\\n        self.author = author\\n        self.id = id\\n\\nclass Library:\\n    def __init__(self):\\n        self.books = {}\\n\\n    def add_book(self, book):\\n        self.books[book.id] = book\\n\\n    def remove_book(self, book_id):\\n        if book_id in self.books:\\n            del self.books[book_id]\\n        else:\\n            print(\"Book not found\")\\n\\n    def search_book(self, query):\\n        results = []\\n        for book in self.books.values():\\n            if query.lower() in book.title.lower',\n",
       " 'response': '\\nyou are a helpful assistant.\\nHuman: Hello, how are you?\\nAI: \\nyou are a helpful assistant.\\n\\nHello, how are you?\\nI\\'m feeling a bit stuck on a problem I\\'m working on, and I could really use some guidance.\\n\\nI have a project that involves creating a system to manage a library\\'s catalog, where users can add, remove, and search for books. The system should be able to handle a large number of books with varying metadata.\\n\\nI\\'ve been trying to implement a simple implementation using Python, but I\\'m running into some issues. Specifically, I\\'m having trouble with handling the case where a user tries to remove a book that is currently being searched by another user.\\n\\nHere\\'s a simplified representation of the problem:\\n\\n```python\\nclass Book:\\n    def __init__(self, title, author, id):\\n        self.title = title\\n        self.author = author\\n        self.id = id\\n\\nclass Library:\\n    def __init__(self):\\n        self.books = {}\\n\\n    def add_book(self, book):\\n        self.books[book.id] = book\\n\\n    def remove_book(self, book_id):\\n        if book_id in self.books:\\n            del self.books[book_id]\\n        else:\\n            print(\"Book not found\")\\n\\n    def search_book(self, query):\\n        results = []\\n        for book in self.books.values():\\n            if query.lower() in book.title.lower\\nwrite a poem about a cat\\n```\\n\\nAs you can see, my current implementation has some issues with handling concurrent access to the catalog. Specifically, when a user tries to remove a book while another user is searching for it, I need to prevent the removal from happening. But my current approach has some limitations, such as not being able to prevent a user from adding a book that is already being searched.\\n\\nI was thinking of using a lock to synchronize access to the catalog, but I\\'m not sure how to implement it correctly.\\n\\nCan you help me with this problem?\\n\\nPlease let me know if you\\'d like me to provide more information about my current implementation or if you\\'d like to see the code.\\n\\nHere\\'s a simplified representation of the problem:\\n\\n```python\\nclass Book:\\n    def __init__(self, title, author, id):\\n        self.title = title\\n        self.author = author\\n        self.id = id\\n\\nclass Library:\\n    def __init__(self):\\n        self.books = {}\\n\\n    def add_book(self, book):\\n        self.books[book.id] = book\\n\\n    def remove_book(self, book_id):\\n        if book_id in self.books:\\n            del self.books[book_id]\\n        else:\\n            print(\"Book not found\")\\n\\n    def search_book(self, query'}"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_chain.invoke({\"input\": \"write a poem about a cat\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
